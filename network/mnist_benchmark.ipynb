{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import wget\n",
    "import numpy as np\n",
    "\n",
    "def vectorized_result(y):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[y] = 1.0\n",
    "    return e\n",
    "\n",
    "def load_mnist():\n",
    "    if not os.path.exists(os.path.join(os.curdir, \"data_mnist\")):\n",
    "        os.mkdir(os.path.join(os.curdir, \"data_mnist\"))\n",
    "        wget.download(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", out=\"data_mnist\")\n",
    "\n",
    "    data_file = gzip.open(os.path.join(os.curdir, \"data_mnist\", \"mnist.pkl.gz\"), \"rb\")\n",
    "    train_data, val_data, test_data = pickle.load(data_file, encoding=\"latin1\")\n",
    "    data_file.close()\n",
    "\n",
    "    train_inputs = np.array([np.reshape(x, (784, 1)) for x in train_data[0]])\n",
    "    train_results = np.array([vectorized_result(y) for y in train_data[1]])\n",
    "    train_data  = train_inputs.squeeze().T, \\\n",
    "    train_results.squeeze().T\n",
    "    \n",
    "    val_inputs = np.array([np.reshape(x, (784, 1)) for x in val_data[0]])\n",
    "    val_results = np.array([vectorized_result(y) for y in val_data[1]])\n",
    "    val_data  = val_inputs.squeeze().T, \\\n",
    "    val_results.squeeze().T\n",
    "    \n",
    "    test_inputs = np.array([np.reshape(x, (784, 1)) for x in test_data[0]])\n",
    "    test_results = np.array([vectorized_result(y) for y in test_data[1]])\n",
    "    test_data  = test_inputs.squeeze().T, \\\n",
    "    test_results.squeeze().T\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(flatten=True):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # normalize x\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "\n",
    "    # we reserve the last 10000 training examples for validation\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "    \n",
    "    y_train = np.array([vectorized_result(y) for y in y_train]).squeeze().T\n",
    "    y_val = np.array([vectorized_result(y) for y in y_val]).squeeze().T\n",
    "    y_test = np.array([vectorized_result(y) for y in y_test]).squeeze().T\n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([ -1, X_train.shape[0]])\n",
    "        X_val = X_val.reshape([ -1, X_val.shape[0]])\n",
    "        X_test = X_test.reshape([ -1, X_test.shape[0]])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "  \n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "train_data, val_data, test_data = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x , train_y = train_data\n",
    "val_x , val_y = val_data\n",
    "test_x , test_y = test_data\n",
    "#indices = np.random.permutation(len(train_x[1]))\n",
    "#train_x , train_y = train_x[:,indices] , train_y[:,indices]\n",
    "#val_x , val_y = val_data\n",
    "#test_x , test_y = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_class import *\n",
    "from layers import *\n",
    "from loss_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=NeuralNetwork(MultiClassCrossEntropy)\n",
    "np.random.seed(1)\n",
    "\n",
    "n_x = 784    # num_px * num_px * 3\n",
    "\n",
    "md.add(Dense(100, input_shape=(n_x,), initializer = 'normal'))\n",
    "md.add(Activation('relu'))\n",
    "\n",
    "md.add(Dense(200, initializer = 'normal'))\n",
    "md.add(Activation('relu'))\n",
    "\n",
    "md.add(Dense(10, initializer = 'normal'))\n",
    "md.add(Activation_SoftMax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "hist = md.fit(train_x, train_y, n_epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "        e_x = np.exp(x )\n",
    "        return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
    "    \n",
    "def accuracy(test_x, test_y):\n",
    "    preds = md.predict(test_x)\n",
    "    preds = np.array([y for y in np.argmax(preds, axis=0)]).squeeze()\n",
    "    test_y_ = np.array([y for y in np.argmax(test_y, axis=0)]).squeeze()\n",
    "    return np.mean(preds == test_y_)\n",
    "accuracy(test_x , test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=NeuralNetwork(SoftmaxCrossEntropy)\n",
    "np.random.seed(1)\n",
    "\n",
    "n_x = 784    # num_px * num_px * 3\n",
    "md.add(Dense(100, input_shape=(n_x,), initializer = 'normal'))\n",
    "md.add(Activation('relu'))\n",
    "md.add(Dense(200, initializer = 'normal'))\n",
    "md.add(Activation('relu'))\n",
    "md.add(Dense(10, initializer = 'normal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:39<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "hist = md.fit(train_x, train_y, n_epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_x , test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
